{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "711a5639-8d4f-4f60-b921-8b13869887ea",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d99837db-0ccb-467d-8726-3c0f01d10fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jennatan/.pyenv/versions/3.8.12/envs/nlp_sentiment/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e417c45-b7bd-4110-b375-30fd5fb33f52",
   "metadata": {},
   "source": [
    "## Get Model Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd525e9-cdd5-466e-bc0f-92d5812c13a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████████████████████████| 768/768 [00:00<00:00, 113kB/s]\n",
      "Downloading: 100%|███████████████████████████| 476M/476M [01:28<00:00, 5.65MB/s]\n",
      "Downloading: 100%|██████████████████████████████| 588/588 [00:00<00:00, 170kB/s]\n",
      "Downloading: 100%|███████████████████████████| 476M/476M [01:26<00:00, 5.76MB/s]\n",
      "Downloading: 100%|██████████████████████████████| 589/589 [00:00<00:00, 213kB/s]\n",
      "Downloading: 100%|███████████████████████████| 476M/476M [01:27<00:00, 5.69MB/s]\n",
      "Downloading: 100%|██████████████████████████████| 593/593 [00:00<00:00, 227kB/s]\n",
      "Downloading: 100%|███████████████████████████| 476M/476M [01:28<00:00, 5.65MB/s]\n",
      "Downloading: 100%|██████████████████████████████| 929/929 [00:00<00:00, 300kB/s]\n",
      "Downloading: 100%|███████████████████████████| 478M/478M [01:30<00:00, 5.56MB/s]\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading: 100%|███████████████████████████| 878k/878k [00:00<00:00, 1.73MB/s]\n",
      "Downloading: 100%|███████████████████████████| 446k/446k [00:00<00:00, 1.13MB/s]\n",
      "Downloading: 100%|█████████████████████████████| 150/150 [00:00<00:00, 58.7kB/s]\n",
      "Downloading: 100%|███████████████████████████| 878k/878k [00:00<00:00, 1.67MB/s]\n",
      "Downloading: 100%|███████████████████████████| 446k/446k [00:00<00:00, 1.09MB/s]\n",
      "Downloading: 100%|█████████████████████████████| 150/150 [00:00<00:00, 51.8kB/s]\n",
      "Downloading: 100%|███████████████████████████| 878k/878k [00:00<00:00, 1.73MB/s]\n",
      "Downloading: 100%|███████████████████████████| 446k/446k [00:00<00:00, 1.41MB/s]\n",
      "Downloading: 100%|█████████████████████████████| 150/150 [00:00<00:00, 52.0kB/s]\n",
      "Downloading: 100%|███████████████████████████| 878k/878k [00:00<00:00, 1.75MB/s]\n",
      "Downloading: 100%|███████████████████████████| 446k/446k [00:00<00:00, 1.12MB/s]\n",
      "Downloading: 100%|█████████████████████████████| 150/150 [00:00<00:00, 42.8kB/s]\n",
      "Downloading: 100%|███████████████████████████| 878k/878k [00:00<00:00, 1.71MB/s]\n",
      "Downloading: 100%|███████████████████████████| 446k/446k [00:00<00:00, 1.11MB/s]\n",
      "Downloading: 100%|█████████████████████████████| 239/239 [00:00<00:00, 71.6kB/s]\n"
     ]
    }
   ],
   "source": [
    "#MODEL1 = \"cardiffnlp/twitter-roberta-base-emoji\"\n",
    "MODEL2 = \"cardiffnlp/twitter-roberta-base-emotion\"\n",
    "MODEL3 = \"cardiffnlp/twitter-roberta-base-hate\"\n",
    "MODEL4 = \"cardiffnlp/twitter-roberta-base-irony\"\n",
    "MODEL5 = \"cardiffnlp/twitter-roberta-base-offensive\"\n",
    "MODEL6 = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "#model1 = AutoModelForSequenceClassification.from_pretrained(MODEL1)\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(MODEL2)\n",
    "model3 = AutoModelForSequenceClassification.from_pretrained(MODEL3)\n",
    "model4 = AutoModelForSequenceClassification.from_pretrained(MODEL4)\n",
    "model5 = AutoModelForSequenceClassification.from_pretrained(MODEL5)\n",
    "model6 = AutoModelForSequenceClassification.from_pretrained(MODEL6)\n",
    "\n",
    "#tokenizer1 = AutoTokenizer.from_pretrained(MODEL1)\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(MODEL2)\n",
    "tokenizer3 = AutoTokenizer.from_pretrained(MODEL3)\n",
    "tokenizer4 = AutoTokenizer.from_pretrained(MODEL4)\n",
    "tokenizer5 = AutoTokenizer.from_pretrained(MODEL5)\n",
    "tokenizer6 = AutoTokenizer.from_pretrained(MODEL6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c874b405-3ac2-4f0c-9758-ebfd476efc89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping_link1 = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/emoji/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link1) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels1 = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "mapping_link2 = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/emotion/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link2) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels2 = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "mapping_link3 = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link3) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels3 = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "mapping_link4 = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/irony/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link4) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels4 = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "mapping_link5 = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link5) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels5 = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "mapping_link6 = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link6) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels6 = [row[1] for row in csvreader if len(row) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830d159-8c48-4e13-a12f-b90e4de09134",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1dd2f629-98a4-495e-bd09-81b16b03c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"PATH TO RAW CSV FILE FROM SNSCRAPE\")\n",
    "#tweets_df = pd.DataFrame(data)\n",
    "#tweets_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23fd471-45c4-4c9a-98da-e635b963e482",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c212fa36-8692-4211-b111-3d491cbab6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    tweets = [i for i in df[\"Text\"]]\n",
    "    preprocessed_tweets = []\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        new_text=[]\n",
    "        \n",
    "        for t in tweet.split(\" \"):\n",
    "            t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "            t = 'http' if t.startswith('http') else t\n",
    "            t = 'http' if '\\nhttp' in t else t \n",
    "            new_text.append(t)\n",
    "            \n",
    "        preprocessed_tweets.append(\" \".join(new_text))\n",
    "    return preprocessed_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ed93d404-913e-4c8c-be8a-00847898c599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def method2_processing(df, prep_df, append=False):\n",
    "    score_list = []\n",
    "    dofi = df\n",
    "    \n",
    "    for text in prep_df:\n",
    "        encoded_input = tokenizer2(text, return_tensors='pt')\n",
    "        output = model2(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        score_list.append(scores)\n",
    "\n",
    "    ranking = np.argsort(score_list[0])\n",
    "    ranking = ranking[::-1]\n",
    "    results = {\"anger\": [], \"sadness\": [], \"optimism\": [], \"joy\": []}\n",
    "\n",
    "    for count, tweet_score in enumerate(score_list):\n",
    "        for i in range(tweet_score.shape[0]):\n",
    "            l = labels2[ranking[i]]\n",
    "            s = tweet_score[ranking[i]]\n",
    "            results[f\"{l}\"].append(np.round(float(s), 4))\n",
    "\n",
    "    if append == True:\n",
    "        \n",
    "        dofi[\"joy\"] = results[\"joy\"]\n",
    "        dofi[\"optimism\"] = results[\"optimism\"]\n",
    "        dofi[\"anger\"] = results[\"anger\"]\n",
    "        dofi[\"sadness\"] = results[\"sadness\"]\n",
    "        \n",
    "        return dofi\n",
    "    \n",
    "    return results                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e0a13a3f-2f9b-4e5f-a46d-a417a01c50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method3_processing(df, prep_df, append=False):\n",
    "    score_list = []\n",
    "    dofi = df\n",
    "    \n",
    "    for text in prep_df:\n",
    "        encoded_input = tokenizer3(text, return_tensors='pt')\n",
    "        output = model3(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        score_list.append(scores)\n",
    "\n",
    "    ranking = np.argsort(score_list[0])\n",
    "    ranking = ranking[::-1]\n",
    "    results = {\"not-hate\": [], \"hate\": []}\n",
    "\n",
    "    for count, tweet_score in enumerate(score_list):\n",
    "        for i in range(tweet_score.shape[0]):\n",
    "            l = labels3[ranking[i]]\n",
    "            s = tweet_score[ranking[i]]\n",
    "            results[f\"{l}\"].append(np.round(float(s), 4))\n",
    "\n",
    "    if append == True:\n",
    "        \n",
    "        dofi[\"not-hate\"] = results[\"not-hate\"]\n",
    "        dofi[\"hate\"] = results[\"hate\"]\n",
    "        \n",
    "        return dofi\n",
    "    \n",
    "    return results                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ec268958-f846-4bea-a2ef-c55f96df3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method4_processing(df, prep_df, append=False):\n",
    "    score_list = []\n",
    "    dofi = df\n",
    "    \n",
    "    for text in prep_df:\n",
    "        encoded_input = tokenizer4(text, return_tensors='pt')\n",
    "        output = model4(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        score_list.append(scores)\n",
    "\n",
    "    ranking = np.argsort(score_list[0])\n",
    "    ranking = ranking[::-1]\n",
    "    results = {\"non_irony\": [], \"irony\": []}\n",
    "\n",
    "    for count, tweet_score in enumerate(score_list):\n",
    "        for i in range(tweet_score.shape[0]):\n",
    "            l = labels4[ranking[i]]\n",
    "            s = tweet_score[ranking[i]]\n",
    "            results[f\"{l}\"].append(np.round(float(s), 4))\n",
    "\n",
    "    if append == True:\n",
    "        \n",
    "        dofi[\"not_irony\"] = results[\"non_irony\"]\n",
    "        dofi[\"irony\"] = results[\"irony\"]\n",
    "        \n",
    "        return dofi\n",
    "    \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ffa69053-e8be-4c2b-83aa-3754f4f0adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method5_processing(df, prep_df, append=False):\n",
    "    score_list = []\n",
    "    dofi = df\n",
    "    \n",
    "    for text in prep_df:\n",
    "        encoded_input = tokenizer5(text, return_tensors='pt')\n",
    "        output = model5(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        score_list.append(scores)\n",
    "\n",
    "    ranking = np.argsort(score_list[0])\n",
    "    ranking = ranking[::-1]\n",
    "    results = {\"not-offensive\": [], \"offensive\": []}\n",
    "\n",
    "    for count, tweet_score in enumerate(score_list):\n",
    "        for i in range(tweet_score.shape[0]):\n",
    "            l = labels5[ranking[i]]\n",
    "            s = tweet_score[ranking[i]]\n",
    "            results[f\"{l}\"].append(np.round(float(s), 4))\n",
    "\n",
    "    if append == True:\n",
    "        \n",
    "        dofi[\"not_offensive\"] = results[\"not-offensive\"]\n",
    "        dofi[\"offensive\"] = results[\"offensive\"]\n",
    "        \n",
    "        return dofi\n",
    "    \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7a04e811-c36b-4778-8be6-093e07a7cbe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def method6_processing(df, prep_df, append=False):\n",
    "    score_list = []\n",
    "    dofi = df\n",
    "    \n",
    "    for text in prep_df:\n",
    "        encoded_input = tokenizer6(text, return_tensors='pt')\n",
    "        output = model6(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        score_list.append(scores)\n",
    "\n",
    "    ranking = np.argsort(score_list[0])\n",
    "    ranking = ranking[::-1]\n",
    "    results = {\"positive\": [], \"neutral\": [], \"negative\": []}\n",
    "\n",
    "    for count, tweet_score in enumerate(score_list):\n",
    "        for i in range(tweet_score.shape[0]):\n",
    "            l = labels6[ranking[i]]\n",
    "            s = tweet_score[ranking[i]]\n",
    "            results[f\"{l}\"].append(np.round(float(s), 4))\n",
    "\n",
    "    if append == True:\n",
    "        \n",
    "        dofi[\"positive\"] = results[\"positive\"]\n",
    "        dofi[\"neutral\"] = results[\"neutral\"]\n",
    "        dofi[\"negative\"] = results[\"negative\"]\n",
    "        \n",
    "        return dofi\n",
    "    \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "61d78ff3-dca7-4e03-b9bf-b45073ab4ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_RoBERTa_processing(df):\n",
    "    prep_df = preprocess(df)\n",
    "    \n",
    "    m2 = method2_processing(df, prep_df, True)\n",
    "    m3 = method3_processing(m2, prep_df, True)\n",
    "    m4 = method4_processing(m3, prep_df, True)\n",
    "    m5 = method5_processing(m4, prep_df, True)\n",
    "    m6 = method6_processing(m5, prep_df, True)\n",
    "    \n",
    "    return m6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c2a43-5802-40a8-a3c2-04c516aa8f7d",
   "metadata": {},
   "source": [
    "## Process Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8ec7e689-24ba-419c-9006-df1b3323b3cb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x7/ljbh3tfd75bf71kcpdq1b5pw0000gn/T/ipykernel_44907/1316031096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dofi[\"joy\"] = results[\"joy\"]\n",
      "/var/folders/x7/ljbh3tfd75bf71kcpdq1b5pw0000gn/T/ipykernel_44907/1316031096.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dofi[\"optimism\"] = results[\"optimism\"]\n",
      "/var/folders/x7/ljbh3tfd75bf71kcpdq1b5pw0000gn/T/ipykernel_44907/1316031096.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dofi[\"anger\"] = results[\"anger\"]\n",
      "/var/folders/x7/ljbh3tfd75bf71kcpdq1b5pw0000gn/T/ipykernel_44907/1316031096.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dofi[\"sadness\"] = results[\"sadness\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Like Count</th>\n",
       "      <th>joy</th>\n",
       "      <th>optimism</th>\n",
       "      <th>anger</th>\n",
       "      <th>sadness</th>\n",
       "      <th>not-hate</th>\n",
       "      <th>hate</th>\n",
       "      <th>not_irony</th>\n",
       "      <th>irony</th>\n",
       "      <th>not_offensive</th>\n",
       "      <th>offensive</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-07 02:12:00+00:00</td>\n",
       "      <td>1533995157858795525</td>\n",
       "      <td>Biden blasted for ‘monumental disaster’ as 11,...</td>\n",
       "      <td>Daily_Express</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0611</td>\n",
       "      <td>0.4864</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.8953</td>\n",
       "      <td>0.1047</td>\n",
       "      <td>0.2895</td>\n",
       "      <td>0.7105</td>\n",
       "      <td>0.7107</td>\n",
       "      <td>0.2893</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.3838</td>\n",
       "      <td>0.6031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-06 11:40:05+00:00</td>\n",
       "      <td>1533775732345823232</td>\n",
       "      <td>More than 45,000 Americans apply to sponsor Uk...</td>\n",
       "      <td>MailOnline</td>\n",
       "      <td>17</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.4267</td>\n",
       "      <td>0.1159</td>\n",
       "      <td>0.1059</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.9180</td>\n",
       "      <td>0.8914</td>\n",
       "      <td>0.1086</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.7758</td>\n",
       "      <td>0.0076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-06-05 03:29:56+00:00</td>\n",
       "      <td>1533289994584002561</td>\n",
       "      <td>Anger as hundreds of refugee children from Ukr...</td>\n",
       "      <td>MailOnline</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.8268</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.1763</td>\n",
       "      <td>0.8237</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.1251</td>\n",
       "      <td>0.8701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-06-04 00:40:42+00:00</td>\n",
       "      <td>1532885015918411777</td>\n",
       "      <td>More than 10,000 migrants have already crossed...</td>\n",
       "      <td>MailOnline</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.2478</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.5535</td>\n",
       "      <td>0.8377</td>\n",
       "      <td>0.1623</td>\n",
       "      <td>0.3815</td>\n",
       "      <td>0.6185</td>\n",
       "      <td>0.7943</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.1613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-06-03 23:30:07+00:00</td>\n",
       "      <td>1532867253988884485</td>\n",
       "      <td>This week marked one hundred days since Russia...</td>\n",
       "      <td>MailOnline</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>0.1641</td>\n",
       "      <td>0.3206</td>\n",
       "      <td>0.1783</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.7448</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.2013</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.6905</td>\n",
       "      <td>0.2920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   Datetime             Tweet Id  \\\n",
       "0           0  2022-06-07 02:12:00+00:00  1533995157858795525   \n",
       "1           1  2022-06-06 11:40:05+00:00  1533775732345823232   \n",
       "2           2  2022-06-05 03:29:56+00:00  1533289994584002561   \n",
       "3           3  2022-06-04 00:40:42+00:00  1532885015918411777   \n",
       "4           4  2022-06-03 23:30:07+00:00  1532867253988884485   \n",
       "\n",
       "                                                Text       Username  \\\n",
       "0  Biden blasted for ‘monumental disaster’ as 11,...  Daily_Express   \n",
       "1  More than 45,000 Americans apply to sponsor Uk...     MailOnline   \n",
       "2  Anger as hundreds of refugee children from Ukr...     MailOnline   \n",
       "3  More than 10,000 migrants have already crossed...     MailOnline   \n",
       "4  This week marked one hundred days since Russia...     MailOnline   \n",
       "\n",
       "   Like Count     joy  optimism   anger  sadness  not-hate    hate  not_irony  \\\n",
       "0           3  0.0147    0.0611  0.4864   0.4378    0.8953  0.1047     0.2895   \n",
       "1          17  0.3515    0.4267  0.1159   0.1059    0.9821  0.0179     0.0820   \n",
       "2          16  0.0090    0.0191  0.8268   0.1451    0.9758  0.0242     0.1763   \n",
       "3          17  0.0449    0.2478  0.1538   0.5535    0.8377  0.1623     0.3815   \n",
       "4          16  0.3370    0.1641  0.3206   0.1783    0.9676  0.0324     0.2552   \n",
       "\n",
       "    irony  not_offensive  offensive  positive  neutral  negative  \n",
       "0  0.7105         0.7107     0.2893    0.0131   0.3838    0.6031  \n",
       "1  0.9180         0.8914     0.1086    0.2166   0.7758    0.0076  \n",
       "2  0.8237         0.8000     0.2000    0.0048   0.1251    0.8701  \n",
       "3  0.6185         0.7943     0.2057    0.0370   0.8017    0.1613  \n",
       "4  0.7448         0.7987     0.2013    0.0175   0.6905    0.2920  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = tweet_RoBERTa_processing(tweets_df)\n",
    "processed_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f56f7ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-27 23:42:06+00:00</td>\n",
       "      <td>1155262113839046661</td>\n",
       "      <td>Mother-to-be is 'heartbroken' after a private ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-07-27 23:37:24+00:00</td>\n",
       "      <td>1155260929900195841</td>\n",
       "      <td>The Chinese village reclaimed by nature: Remot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-07-27 23:34:56+00:00</td>\n",
       "      <td>1155260311345270784</td>\n",
       "      <td>Disney actress who voiced Minnie Mouse and mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-07-27 23:29:00+00:00</td>\n",
       "      <td>1155258816679690240</td>\n",
       "      <td>'My Birthday boy' Louise Redknapp reunites wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-07-27 23:23:00+00:00</td>\n",
       "      <td>1155257306784948225</td>\n",
       "      <td>'I miss him' Debbie McGee reveals how she ‘got...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247956</th>\n",
       "      <td>247956</td>\n",
       "      <td>2018-07-28 00:22:01+00:00</td>\n",
       "      <td>1023000589750464512</td>\n",
       "      <td>These are the WARNING signs your baby is dange...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247957</th>\n",
       "      <td>247957</td>\n",
       "      <td>2018-07-28 00:21:04+00:00</td>\n",
       "      <td>1023000351593652224</td>\n",
       "      <td>Mysterious tar decorations scrawled on the bon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247958</th>\n",
       "      <td>247958</td>\n",
       "      <td>2018-07-28 00:09:00+00:00</td>\n",
       "      <td>1022997313021771776</td>\n",
       "      <td>Best supplements for high blood pressure: 2p a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247959</th>\n",
       "      <td>247959</td>\n",
       "      <td>2018-07-28 00:02:00+00:00</td>\n",
       "      <td>1022995550994669569</td>\n",
       "      <td>Brit mum’s tearful call home as she swam for h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247960</th>\n",
       "      <td>247960</td>\n",
       "      <td>2018-07-28 00:00:00+00:00</td>\n",
       "      <td>1022995047338336257</td>\n",
       "      <td>#LoveIsland: Alex George and Alexandra Cane SA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247961 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                   Datetime             Tweet Id  \\\n",
       "0                0  2019-07-27 23:42:06+00:00  1155262113839046661   \n",
       "1                1  2019-07-27 23:37:24+00:00  1155260929900195841   \n",
       "2                2  2019-07-27 23:34:56+00:00  1155260311345270784   \n",
       "3                3  2019-07-27 23:29:00+00:00  1155258816679690240   \n",
       "4                4  2019-07-27 23:23:00+00:00  1155257306784948225   \n",
       "...            ...                        ...                  ...   \n",
       "247956      247956  2018-07-28 00:22:01+00:00  1023000589750464512   \n",
       "247957      247957  2018-07-28 00:21:04+00:00  1023000351593652224   \n",
       "247958      247958  2018-07-28 00:09:00+00:00  1022997313021771776   \n",
       "247959      247959  2018-07-28 00:02:00+00:00  1022995550994669569   \n",
       "247960      247960  2018-07-28 00:00:00+00:00  1022995047338336257   \n",
       "\n",
       "                                                     Text  \n",
       "0       Mother-to-be is 'heartbroken' after a private ...  \n",
       "1       The Chinese village reclaimed by nature: Remot...  \n",
       "2       Disney actress who voiced Minnie Mouse and mar...  \n",
       "3       'My Birthday boy' Louise Redknapp reunites wit...  \n",
       "4       'I miss him' Debbie McGee reveals how she ‘got...  \n",
       "...                                                   ...  \n",
       "247956  These are the WARNING signs your baby is dange...  \n",
       "247957  Mysterious tar decorations scrawled on the bon...  \n",
       "247958  Best supplements for high blood pressure: 2p a...  \n",
       "247959  Brit mum’s tearful call home as she swam for h...  \n",
       "247960  #LoveIsland: Alex George and Alexandra Cane SA...  \n",
       "\n",
       "[247961 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('18_19_all_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd98f8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-07-27 23:52:00+00:00</td>\n",
       "      <td>1287898563687510016</td>\n",
       "      <td>#Outlander’s Sam Heughan announces new project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-27 23:46:02+00:00</td>\n",
       "      <td>1287897064983220224</td>\n",
       "      <td>Megan Barton Hanson sends temperatures soaring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-07-27 23:45:00+00:00</td>\n",
       "      <td>1287896801916399622</td>\n",
       "      <td>Emily Maitlis' Newsnight co-star admits they '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-07-27 23:44:00+00:00</td>\n",
       "      <td>1287896550371258368</td>\n",
       "      <td>What is this 'black cube' seen near the Sun? I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-07-27 23:42:50+00:00</td>\n",
       "      <td>1287896259408338948</td>\n",
       "      <td>Britain’s crumbling jails struggle to cope wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89155</th>\n",
       "      <td>89155</td>\n",
       "      <td>2020-04-07 22:11:00+00:00</td>\n",
       "      <td>1247648093102698496</td>\n",
       "      <td>🐰 COMPETITION ALERT 🐰\\n\\nOnly 1 day left to en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89156</th>\n",
       "      <td>89156</td>\n",
       "      <td>2020-04-07 22:10:00+00:00</td>\n",
       "      <td>1247647841541070850</td>\n",
       "      <td>You won't be able to look away from this massi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89157</th>\n",
       "      <td>89157</td>\n",
       "      <td>2020-04-07 22:07:00+00:00</td>\n",
       "      <td>1247647086448758784</td>\n",
       "      <td>‘It was bound to happen’ This Morning host Phi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89158</th>\n",
       "      <td>89158</td>\n",
       "      <td>2020-04-07 22:02:48+00:00</td>\n",
       "      <td>1247646029769576449</td>\n",
       "      <td>Britney Spears shares sexy snaps of toned tumm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89159</th>\n",
       "      <td>89159</td>\n",
       "      <td>2020-04-07 22:01:46+00:00</td>\n",
       "      <td>1247645768787415048</td>\n",
       "      <td>The Walking Dead: Fans fume as Maggie's return...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89160 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                   Datetime             Tweet Id  \\\n",
       "0               0  2020-07-27 23:52:00+00:00  1287898563687510016   \n",
       "1               1  2020-07-27 23:46:02+00:00  1287897064983220224   \n",
       "2               2  2020-07-27 23:45:00+00:00  1287896801916399622   \n",
       "3               3  2020-07-27 23:44:00+00:00  1287896550371258368   \n",
       "4               4  2020-07-27 23:42:50+00:00  1287896259408338948   \n",
       "...           ...                        ...                  ...   \n",
       "89155       89155  2020-04-07 22:11:00+00:00  1247648093102698496   \n",
       "89156       89156  2020-04-07 22:10:00+00:00  1247647841541070850   \n",
       "89157       89157  2020-04-07 22:07:00+00:00  1247647086448758784   \n",
       "89158       89158  2020-04-07 22:02:48+00:00  1247646029769576449   \n",
       "89159       89159  2020-04-07 22:01:46+00:00  1247645768787415048   \n",
       "\n",
       "                                                    Text  \n",
       "0      #Outlander’s Sam Heughan announces new project...  \n",
       "1      Megan Barton Hanson sends temperatures soaring...  \n",
       "2      Emily Maitlis' Newsnight co-star admits they '...  \n",
       "3      What is this 'black cube' seen near the Sun? I...  \n",
       "4      Britain’s crumbling jails struggle to cope wit...  \n",
       "...                                                  ...  \n",
       "89155  🐰 COMPETITION ALERT 🐰\\n\\nOnly 1 day left to en...  \n",
       "89156  You won't be able to look away from this massi...  \n",
       "89157  ‘It was bound to happen’ This Morning host Phi...  \n",
       "89158  Britney Spears shares sexy snaps of toned tumm...  \n",
       "89159  The Walking Dead: Fans fume as Maggie's return...  \n",
       "\n",
       "[89160 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('19_20_all_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3115d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
